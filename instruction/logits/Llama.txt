# coding=utf-8

CUDA_VISIBLE_DEVICES=0 python3 -m experiments.evaluate_seq_logits \
    --alg_name=MEMIT \
    --model_name=llama \
    --model_path=/data/swh/UER/TencentPretrain/models/llama/7b_new  \
    --hparams_fname=llama_7b.json \
   --num_edits=1000 \
    --dataset_size_limit=1000 --ds_name mcf --loc_data_size 100 --new_prompt --select_standard key  --neuron_num 20000  --orig_loc --final_loc --real_edit --after_edit --top_number 1000;